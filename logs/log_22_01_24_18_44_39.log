[2024-01-22 18:47:19,593 - root INFO ] : uer is on landing page .
[2024-01-22 18:47:22,421 - django.request WARNING ] : Not Found: /favicon.ico
[2024-01-22 18:47:27,234 - root INFO ] : user is on prediction page
[2024-01-22 18:47:30,810 - root INFO ] : user is visiting all prediction page
[2024-01-22 18:47:34,673 - root INFO ] : uer is on landing page .
[2024-01-22 18:47:36,482 - root INFO ] : user is on model training page
[2024-01-22 18:47:41,679 - root INFO ] : user is starting the training pipeline
[2024-01-22 18:47:41,679 - root INFO ] : pipeline is about to start 
[2024-01-22 18:47:41,683 - root INFO ] : ============================================================ Training pipeline started ============================================================
[2024-01-22 18:47:41,690 - root INFO ] : user is on model training page
[2024-01-22 18:47:41,723 - root INFO ] : Pipeline experiments : Experiments(experiment_id='5c559599-a63d-448d-b775-2ccaa2953ac3', running_status=True, start_time=datetime.datetime(2024, 1, 22, 18, 47, 41, 721115), stop_time=None, execution_time=None, message='Pipeline has been started', accuracy=None, is_model_accepted=None)
[2024-01-22 18:47:41,723 - root INFO ] : saving experiment data in database
[2024-01-22 18:47:42,099 - root INFO ] : experiment data got saved into database
[2024-01-22 18:47:42,099 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Ingestion component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:47:42,106 - root INFO ] : downloading dataset from url : https://github.com/Sahulinkan7/dataset_repo/raw/main/concrete_data.zip
[2024-01-22 18:47:42,106 - root INFO ] : dataset got downloaded and saved into path : artifacts\data_ingestion\downloaded_data\concrete.zip
[2024-01-22 18:47:42,106 - root INFO ] : extracting downloaded zip file from artifacts\data_ingestion\downloaded_data\concrete.zip
[2024-01-22 18:47:42,250 - root INFO ] : dataset got extracted to the path : artifacts\data_ingestion\extracted_data\concrete_data.csv
[2024-01-22 18:47:42,250 - root INFO ] : spliting extracted dataset into train data and test data set.
[2024-01-22 18:47:42,250 - root INFO ] : reading dataset from path : artifacts\data_ingestion\extracted_data\concrete_data.csv
[2024-01-22 18:47:42,459 - root INFO ] : reading dataframe column names : Index(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer',
       'coarse_aggregate', 'fine_aggregate', 'age',
       'concrete_compressive_strength'],
      dtype='object')
[2024-01-22 18:47:42,565 - root INFO ] : dataframe is as 
    cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age  concrete_compressive_strength
0   540.0                 0.0      0.0  162.0               2.5            1040.0           676.0   28                          79.99
1   540.0                 0.0      0.0  162.0               2.5            1055.0           676.0   28                          61.89
2   332.5               142.5      0.0  228.0               0.0             932.0           594.0  270                          40.27
[2024-01-22 18:47:42,599 - root INFO ] : dataframe splitted into train dataframe and test dataframe 
[2024-01-22 18:47:42,599 - root INFO ] : train data shape : (824, 9) and test data shape : (206, 9)
[2024-01-22 18:47:42,732 - root INFO ] : train dataframe saved in file path  : artifacts\data_ingestion\splitted_dataset\train_dataset\train.csv
[2024-01-22 18:47:42,732 - root INFO ] : test dataframe saved in file path : artifacts\data_ingestion\splitted_dataset\test_dataset\test.csv
[2024-01-22 18:47:42,732 - root INFO ] : data ingestion artifacts 
 DataIngestionArtifact(raw_data_path='artifacts\\data_ingestion\\extracted_data\\concrete_data.csv', train_data_path='artifacts\\data_ingestion\\splitted_dataset\\train_dataset\\train.csv', test_data_path='artifacts\\data_ingestion\\splitted_dataset\\test_dataset\\test.csv')
[2024-01-22 18:47:42,732 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Ingestion component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:47:42,732 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data validation component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:47:42,732 - root INFO ] : Data Validation object created
[2024-01-22 18:47:42,732 - root INFO ] : Data validation artifact directory created 
[2024-01-22 18:47:42,732 - root INFO ] : validating all columns inside dataframe
[2024-01-22 18:47:42,754 - root INFO ] : columns from schema file : dict_keys(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate', 'age', 'concrete_compressive_strength'])
[2024-01-22 18:47:42,754 - root INFO ] : columns from dataframe : ['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate', 'age', 'concrete_compressive_strength']
[2024-01-22 18:47:42,762 - root INFO ] : validation status is True
[2024-01-22 18:47:42,762 - root INFO ] : data validation artifacts 
 DataValidationArtifact(data_validation_status=True, data_validation_report_filepath='artifacts\\data_validation\\report.yaml', validated_dataset_filepath='artifacts\\data_ingestion\\extracted_data\\concrete_data.csv', validated_train_filepath='artifacts\\data_ingestion\\splitted_dataset\\train_dataset\\train.csv', validated_test_filepath='artifacts\\data_ingestion\\splitted_dataset\\test_dataset\\test.csv')
[2024-01-22 18:47:42,762 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data validation component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:47:42,762 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Transformation component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:47:42,762 - root INFO ] :  reading dataframe 
[2024-01-22 18:47:42,962 - root INFO ] : creating data transformation object
[2024-01-22 18:47:42,962 - root INFO ] : creating pipeline for data transformer object
[2024-01-22 18:47:42,977 - root INFO ] : pipeline for data transformer created
[2024-01-22 18:47:42,977 - root INFO ] : data transformer object created
[2024-01-22 18:47:42,977 - root INFO ] : droping target columns from training dataframe 
[2024-01-22 18:47:43,095 - root INFO ] : columns for model training are 
 Index(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer',
       'coarse_aggregate', 'fine_aggregate', 'age'],
      dtype='object')
[2024-01-22 18:47:43,095 - root INFO ] : target feature concrete_compressive_strength dropped from train dataframe
[2024-01-22 18:47:43,095 - root INFO ] : input feature train dataframe and target feature dataframe created successfully
[2024-01-22 18:47:43,095 - root INFO ] : target feature dropped from test dataframe
[2024-01-22 18:47:43,095 - root INFO ] : input feature test dataframe and target feature dataframe created successfully
[2024-01-22 18:47:43,095 - root INFO ] : before transforming train input features    cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age
0   331.0                 0.0      0.0  192.0               0.0            1025.0           821.0    7
1   255.0                 0.0      0.0  192.0               0.0             889.8           945.0   90
[2024-01-22 18:47:43,095 - root INFO ] : fitting preprocessor object with input train feature dataframe to create tranformer object
[2024-01-22 18:47:43,126 - root INFO ] : input features of train and test dataframe got transformed
[2024-01-22 18:47:43,126 - root INFO ] : saving object in file path : artifacts\data_transformation\transformed_object\preprocessor.pkl
[2024-01-22 18:47:43,179 - root INFO ] : preprocessor object got saved successfully .
[2024-01-22 18:47:43,179 - root INFO ] : saving numpy array in path : artifacts\data_transformation\transformed_data\train.npy
[2024-01-22 18:47:43,179 - root INFO ] : saving numpy array in path : artifacts\data_transformation\transformed_data\test.npy
[2024-01-22 18:47:43,214 - root INFO ] : Transformed train array and test array got saved successfully
[2024-01-22 18:47:43,214 - root INFO ] : data transformation artifacts : DataTransformationArtifact(preprocessor_filepath='artifacts\\data_transformation\\transformed_object\\preprocessor.pkl', transformed_train_filepath='artifacts\\data_transformation\\transformed_data\\train.npy', transformed_test_filepath='artifacts\\data_transformation\\transformed_data\\test.npy')
[2024-01-22 18:47:43,214 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Transformation component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:47:43,214 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Model Training component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:47:43,214 - root INFO ] : splitting train array and test array input and target feature 
[2024-01-22 18:47:43,214 - root INFO ] : loading numpy array data from artifacts\data_transformation\transformed_data\train.npy
[2024-01-22 18:47:43,246 - root INFO ] : loading numpy array data from artifacts\data_transformation\transformed_data\test.npy
[2024-01-22 18:47:43,262 - root INFO ] : splitting train and test array to independent and dependent features 
[2024-01-22 18:47:43,262 - root INFO ] : loading object from file path : artifacts\data_transformation\transformed_object\preprocessor.pkl
[2024-01-22 18:47:43,307 - root INFO ] : starting model training and evaluation 
[2024-01-22 18:47:45,825 - root INFO ] : models evaluation scores as 
 {'LinearRegression': 0.6296146920759185, 'Ridge': 0.6304793844698795, 'Lasso': 0.5963200779448017, 'ElasticNet': 0.5177799912596457, 'DecisionTreeRegressior': 0.8648702470028129, 'RandomForestRegressor': 0.9242969017104079, 'SVR': 0.6770116250771685}
[2024-01-22 18:47:52,785 - root INFO ] : user is starting the training pipeline
[2024-01-22 18:47:52,787 - root ERROR ] : pipeline can not be started , pipeline is already running
[2024-01-22 18:48:05,263 - root INFO ] : user is on model training page
[2024-01-22 18:48:08,141 - root INFO ] : user is starting the training pipeline
[2024-01-22 18:48:08,148 - root ERROR ] : pipeline can not be started , pipeline is already running
[2024-01-22 18:48:31,095 - root INFO ] : user is on prediction page
[2024-01-22 18:48:35,653 - root INFO ] : user is visiting all prediction page
[2024-01-22 18:48:40,680 - root INFO ] : user is on prediction page
[2024-01-22 18:48:43,112 - root INFO ] : user is visiting all prediction page
[2024-01-22 18:48:45,088 - root INFO ] : uer is on landing page .
[2024-01-22 18:48:49,469 - root INFO ] : accuracy of best tuned model is 0.922879664060874
[2024-01-22 18:48:49,469 - root INFO ] : best model found 
[2024-01-22 18:48:49,469 - root INFO ] : saving model in path : artifacts\model_trainer\trained_model\model.pkl
[2024-01-22 18:48:49,469 - root INFO ] : saving object in file path : artifacts\model_trainer\trained_model\model.pkl
[2024-01-22 18:48:49,540 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Model Training component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 18:48:49,540 - root INFO ] : updating experiment data in database
[2024-01-22 18:48:49,556 - root INFO ] : {'experiment_id': '5c559599-a63d-448d-b775-2ccaa2953ac3', 'running_status': False, 'start_time': datetime.datetime(2024, 1, 22, 18, 47, 41, 721115), 'stop_time': datetime.datetime(2024, 1, 22, 18, 48, 49, 540975), 'execution_time': datetime.timedelta(seconds=67, microseconds=819860), 'message': 'Pipeline completed', 'accuracy': 0.922879664060874, 'is_model_accepted': True}
[2024-01-22 18:48:49,665 - root INFO ] : experiment data got updated in db
[2024-01-22 18:48:49,665 - root INFO ] : ============================================================ Training pipeline completed ============================================================
[2024-01-22 18:50:56,202 - root INFO ] : user is on prediction page
[2024-01-22 18:51:00,762 - root INFO ] : user is visiting all prediction page
[2024-01-22 18:51:28,278 - root INFO ] : user is on prediction page
[2024-01-22 18:52:09,320 - root INFO ] : creating new dataframe 
[2024-01-22 18:52:09,320 - root INFO ] : Index(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer',
       'coarse_aggregate', 'fine_aggregate', 'age'],
      dtype='object')
[2024-01-22 18:52:09,320 - root INFO ] : 
   cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age
0     540                   0        0    165                 2              1014             680   24
[2024-01-22 18:52:09,328 - root INFO ] : dataframe for prediction is 
    cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age
0     540                   0        0    165                 2              1014             680   24
[2024-01-22 18:52:09,328 - root INFO ] : doing single data predition 
[2024-01-22 18:52:09,328 - root INFO ] : loading object from file path : artifacts\model_trainer\trained_model\model.pkl
[2024-01-22 18:52:09,369 - root INFO ] : predicted output is [74.19133333]
[2024-01-22 18:52:09,518 - root INFO ] : user clicked on predict button to predict the cement strength and the predicted value is 74.19133333333333
[2024-01-22 18:52:18,226 - root INFO ] : user is visiting all prediction page
[2024-01-22 18:52:26,299 - root INFO ] : user is visiting all prediction page
[2024-01-22 18:52:29,202 - root INFO ] : user is visiting all prediction page
[2024-01-22 18:52:31,340 - root INFO ] : user is on model training page
[2024-01-22 18:53:15,435 - root INFO ] : uer is on landing page .
[2024-01-22 18:59:04,451 - root INFO ] : user is on model training page
[2024-01-22 19:01:40,714 - root INFO ] : user is starting the training pipeline
[2024-01-22 19:01:40,714 - root INFO ] : pipeline is about to start 
[2024-01-22 19:01:40,714 - root INFO ] : ============================================================ Training pipeline started ============================================================
[2024-01-22 19:01:40,714 - root INFO ] : Pipeline experiments : Experiments(experiment_id='2dae798c-6b65-4ead-94d6-edb858b3d7ab', running_status=True, start_time=datetime.datetime(2024, 1, 22, 19, 1, 40, 714424), stop_time=None, execution_time=None, message='Pipeline has been started', accuracy=None, is_model_accepted=None)
[2024-01-22 19:01:40,714 - root INFO ] : saving experiment data in database
[2024-01-22 19:01:40,732 - root INFO ] : user is on model training page
[2024-01-22 19:01:40,994 - root INFO ] : experiment data got saved into database
[2024-01-22 19:01:40,994 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Ingestion component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:01:40,994 - root INFO ] : downloading dataset from url : https://github.com/Sahulinkan7/dataset_repo/raw/main/concrete_data.zip
[2024-01-22 19:01:40,998 - root INFO ] : dataset got downloaded and saved into path : artifacts\data_ingestion\downloaded_data\concrete.zip
[2024-01-22 19:01:40,998 - root INFO ] : extracting downloaded zip file from artifacts\data_ingestion\downloaded_data\concrete.zip
[2024-01-22 19:01:41,003 - root INFO ] : dataset got extracted to the path : artifacts\data_ingestion\extracted_data\concrete_data.csv
[2024-01-22 19:01:41,003 - root INFO ] : spliting extracted dataset into train data and test data set.
[2024-01-22 19:01:41,003 - root INFO ] : reading dataset from path : artifacts\data_ingestion\extracted_data\concrete_data.csv
[2024-01-22 19:01:41,040 - root INFO ] : reading dataframe column names : Index(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer',
       'coarse_aggregate', 'fine_aggregate', 'age',
       'concrete_compressive_strength'],
      dtype='object')
[2024-01-22 19:01:41,083 - root INFO ] : dataframe is as 
    cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age  concrete_compressive_strength
0   540.0                 0.0      0.0  162.0               2.5            1040.0           676.0   28                          79.99
1   540.0                 0.0      0.0  162.0               2.5            1055.0           676.0   28                          61.89
2   332.5               142.5      0.0  228.0               0.0             932.0           594.0  270                          40.27
[2024-01-22 19:01:41,085 - root INFO ] : dataframe splitted into train dataframe and test dataframe 
[2024-01-22 19:01:41,085 - root INFO ] : train data shape : (824, 9) and test data shape : (206, 9)
[2024-01-22 19:01:41,101 - root INFO ] : train dataframe saved in file path  : artifacts\data_ingestion\splitted_dataset\train_dataset\train.csv
[2024-01-22 19:01:41,101 - root INFO ] : test dataframe saved in file path : artifacts\data_ingestion\splitted_dataset\test_dataset\test.csv
[2024-01-22 19:01:41,101 - root INFO ] : data ingestion artifacts 
 DataIngestionArtifact(raw_data_path='artifacts\\data_ingestion\\extracted_data\\concrete_data.csv', train_data_path='artifacts\\data_ingestion\\splitted_dataset\\train_dataset\\train.csv', test_data_path='artifacts\\data_ingestion\\splitted_dataset\\test_dataset\\test.csv')
[2024-01-22 19:01:41,101 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Ingestion component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:01:41,101 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data validation component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:01:41,101 - root INFO ] : Data Validation object created
[2024-01-22 19:01:41,101 - root INFO ] : Data validation artifact directory created 
[2024-01-22 19:01:41,101 - root INFO ] : validating all columns inside dataframe
[2024-01-22 19:01:41,115 - root INFO ] : columns from schema file : dict_keys(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate', 'age', 'concrete_compressive_strength'])
[2024-01-22 19:01:41,115 - root INFO ] : columns from dataframe : ['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate', 'age', 'concrete_compressive_strength']
[2024-01-22 19:01:41,124 - root INFO ] : validation status is True
[2024-01-22 19:01:41,125 - root INFO ] : data validation artifacts 
 DataValidationArtifact(data_validation_status=True, data_validation_report_filepath='artifacts\\data_validation\\report.yaml', validated_dataset_filepath='artifacts\\data_ingestion\\extracted_data\\concrete_data.csv', validated_train_filepath='artifacts\\data_ingestion\\splitted_dataset\\train_dataset\\train.csv', validated_test_filepath='artifacts\\data_ingestion\\splitted_dataset\\test_dataset\\test.csv')
[2024-01-22 19:01:41,125 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data validation component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:01:41,125 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Transformation component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:01:41,126 - root INFO ] :  reading dataframe 
[2024-01-22 19:01:41,150 - root INFO ] : creating data transformation object
[2024-01-22 19:01:41,150 - root INFO ] : creating pipeline for data transformer object
[2024-01-22 19:01:41,150 - root INFO ] : pipeline for data transformer created
[2024-01-22 19:01:41,158 - root INFO ] : data transformer object created
[2024-01-22 19:01:41,158 - root INFO ] : droping target columns from training dataframe 
[2024-01-22 19:01:41,166 - root INFO ] : columns for model training are 
 Index(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer',
       'coarse_aggregate', 'fine_aggregate', 'age'],
      dtype='object')
[2024-01-22 19:01:41,166 - root INFO ] : target feature concrete_compressive_strength dropped from train dataframe
[2024-01-22 19:01:41,166 - root INFO ] : input feature train dataframe and target feature dataframe created successfully
[2024-01-22 19:01:41,166 - root INFO ] : target feature dropped from test dataframe
[2024-01-22 19:01:41,166 - root INFO ] : input feature test dataframe and target feature dataframe created successfully
[2024-01-22 19:01:41,174 - root INFO ] : before transforming train input features    cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age
0   331.0                 0.0      0.0  192.0               0.0            1025.0           821.0    7
1   255.0                 0.0      0.0  192.0               0.0             889.8           945.0   90
[2024-01-22 19:01:41,174 - root INFO ] : fitting preprocessor object with input train feature dataframe to create tranformer object
[2024-01-22 19:01:41,182 - root INFO ] : input features of train and test dataframe got transformed
[2024-01-22 19:01:41,190 - root INFO ] : saving object in file path : artifacts\data_transformation\transformed_object\preprocessor.pkl
[2024-01-22 19:01:41,193 - root INFO ] : preprocessor object got saved successfully .
[2024-01-22 19:01:41,193 - root INFO ] : saving numpy array in path : artifacts\data_transformation\transformed_data\train.npy
[2024-01-22 19:01:41,193 - root INFO ] : saving numpy array in path : artifacts\data_transformation\transformed_data\test.npy
[2024-01-22 19:01:41,193 - root INFO ] : Transformed train array and test array got saved successfully
[2024-01-22 19:01:41,193 - root INFO ] : data transformation artifacts : DataTransformationArtifact(preprocessor_filepath='artifacts\\data_transformation\\transformed_object\\preprocessor.pkl', transformed_train_filepath='artifacts\\data_transformation\\transformed_data\\train.npy', transformed_test_filepath='artifacts\\data_transformation\\transformed_data\\test.npy')
[2024-01-22 19:01:41,193 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Data Transformation component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:01:41,193 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Model Training component started >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:01:41,193 - root INFO ] : splitting train array and test array input and target feature 
[2024-01-22 19:01:41,193 - root INFO ] : loading numpy array data from artifacts\data_transformation\transformed_data\train.npy
[2024-01-22 19:01:41,211 - root INFO ] : loading numpy array data from artifacts\data_transformation\transformed_data\test.npy
[2024-01-22 19:01:41,227 - root INFO ] : splitting train and test array to independent and dependent features 
[2024-01-22 19:01:41,227 - root INFO ] : loading object from file path : artifacts\data_transformation\transformed_object\preprocessor.pkl
[2024-01-22 19:01:41,227 - root INFO ] : starting model training and evaluation 
[2024-01-22 19:01:43,477 - root INFO ] : models evaluation scores as 
 {'LinearRegression': 0.6296146920759185, 'Ridge': 0.6304793844698795, 'Lasso': 0.5963200779448017, 'ElasticNet': 0.5177799912596457, 'DecisionTreeRegressior': 0.8736333999369593, 'RandomForestRegressor': 0.9225461210177344, 'SVR': 0.6770116250771685}
[2024-01-22 19:02:32,251 - root INFO ] : user is on model training page
[2024-01-22 19:02:35,292 - root INFO ] : user is starting the training pipeline
[2024-01-22 19:02:35,292 - root ERROR ] : pipeline can not be started , pipeline is already running
[2024-01-22 19:02:48,719 - root INFO ] : accuracy of best tuned model is 0.9151417464413377
[2024-01-22 19:02:48,719 - root INFO ] : best model found 
[2024-01-22 19:02:48,719 - root INFO ] : saving model in path : artifacts\model_trainer\trained_model\model.pkl
[2024-01-22 19:02:48,719 - root INFO ] : saving object in file path : artifacts\model_trainer\trained_model\model.pkl
[2024-01-22 19:02:48,719 - root INFO ] : <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Model Training component completed >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
[2024-01-22 19:02:48,719 - root INFO ] : updating experiment data in database
[2024-01-22 19:02:48,719 - root INFO ] : {'experiment_id': '2dae798c-6b65-4ead-94d6-edb858b3d7ab', 'running_status': False, 'start_time': datetime.datetime(2024, 1, 22, 19, 1, 40, 714424), 'stop_time': datetime.datetime(2024, 1, 22, 19, 2, 48, 719964), 'execution_time': datetime.timedelta(seconds=68, microseconds=5540), 'message': 'Pipeline completed', 'accuracy': 0.9151417464413377, 'is_model_accepted': True}
[2024-01-22 19:02:48,829 - root INFO ] : experiment data got updated in db
[2024-01-22 19:02:48,829 - root INFO ] : ============================================================ Training pipeline completed ============================================================
[2024-01-22 19:03:54,598 - root INFO ] : user is on prediction page
[2024-01-22 19:06:18,011 - root INFO ] : user is visiting all prediction page
[2024-01-22 19:07:09,497 - root INFO ] : creating new dataframe 
[2024-01-22 19:07:09,497 - root INFO ] : Index(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer',
       'coarse_aggregate', 'fine_aggregate', 'age'],
      dtype='object')
[2024-01-22 19:07:09,505 - root INFO ] : 
   cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age
0     520                   0        0    166                 2              1011             674   29
[2024-01-22 19:07:09,505 - root INFO ] : dataframe for prediction is 
    cement  blast_furnace_slag  fly_ash  water  superplasticizer  coarse_aggregate  fine_aggregate  age
0     520                   0        0    166                 2              1011             674   29
[2024-01-22 19:07:09,505 - root INFO ] : doing single data predition 
[2024-01-22 19:07:09,505 - root INFO ] : loading object from file path : artifacts\model_trainer\trained_model\model.pkl
[2024-01-22 19:07:09,553 - root INFO ] : predicted output is [64.8555]
[2024-01-22 19:07:09,688 - root INFO ] : user clicked on predict button to predict the cement strength and the predicted value is 64.85550000000002
[2024-01-22 19:07:53,525 - root INFO ] : user is visiting all prediction page
[2024-01-22 19:11:31,170 - root INFO ] : user is on model training page
[2024-01-22 19:28:56,836 - root INFO ] : user is on model training page
